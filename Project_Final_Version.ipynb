{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import random\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL FUNCTIONS\n",
    "\n",
    "def changeclass(input):\n",
    "    temp = set(input)\n",
    "    dict_classes = {k: i for i, k in enumerate(temp)}\n",
    "    num_classes = [dict_classes[c] for c in input]\n",
    "    return num_classes\n",
    "\n",
    "def showclass(input):\n",
    "    labels, values = zip(*collections.Counter(input).items())\n",
    "    indexes = np.arange(len(labels))\n",
    "    plt.bar(values, indexes, 1)\n",
    "    plt.yticks(indexes, labels)\n",
    "    plt.plot(values,labels,linewidth=3)\n",
    "    plt.show()\n",
    "    \n",
    "def showaccuracy(per_class_accuracy, per_class_accuracy_ET):\n",
    "    for i in range(0,21):\n",
    "        Count = collections.Counter(per_class_accuracy[i])\n",
    "        if Count[0] == 0 and Count[1] == 0:\n",
    "            print(\"%d : No Samples\" % i)\n",
    "        else:\n",
    "            print(\"%d : %0.2f , True: %d , False: %d\" % (i,round((Count[1]/(Count[1] + Count[0])) * 100,2), Count[1], Count[0]))\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\")        \n",
    "    for i in range(0,21):\n",
    "        Count_ET = collections.Counter(per_class_accuracy_ET[i])\n",
    "        if Count_ET[0] == 0 and Count_ET[1] == 0:\n",
    "            print(\"%d : No Samples\" % i)\n",
    "        else:\n",
    "            print(\"%d : %0.2f , True: %d , False: %d\" % (i,round((Count_ET[1]/(Count_ET[1] + Count_ET[0])) * 100,2), Count_ET[1], Count_ET[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "N_BINS = 60                                   # USED IN NORMALIZING THE DATA TO COMMON FORM\n",
    "TRAINED_DATA = 25000                          # HOW MANY DATA DO WE WANT TO TRAIN\n",
    "COMBINED_CLASSIFICATION_SAMPLES = 30000       # HOW MANY SAMPLES IN COMBINED CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ THE DATA\n",
    "data = json.load(open('MoNA-export-GC-MS_Spectra.json', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAT CLEAN_DATA ONLY WITH SUBCLASS, CLASS, SUPERCLASS, SPECTRUM [VALUE, TEMPERATURE] INFORMATIONS\n",
    "#we only care about those features and labels since or objective is to classify data(spectrum) by labels (subclass,class,superclass)\n",
    "clean_data = []\n",
    "#we add the data to the dictionary \"clean_data\"\n",
    "\n",
    "for d in data:\n",
    "  dict_i = {'class': '', 'subclass': '', 'superclass': ''}\n",
    "  for c in d['compound'][0]['classification']:\n",
    "    if c['name'] == 'class':\n",
    "        dict_i['class'] = c['value']\n",
    "    if c['name'] == 'subclass':\n",
    "            dict_i['subclass'] = c['value']\n",
    "    if c['name'] == 'superclass':\n",
    "            dict_i['superclass'] = c['value']\n",
    "    dict_i['spectrum'] = d['spectrum']\n",
    "    clean_data.append(dict_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAT CLEAN_DATA_BINNED WHICH NORMALIZE DATA TO COMMON FORM (EVERY 'POINT' HAS 60 VALUES OF 'PEAKS' IN SPECTRUM)\n",
    "plot = False #activate or deactivate ploting\n",
    "\n",
    "bins = np.linspace(0, 300, N_BINS) #our data mostly goes from 50 to 250 but has some exceptions so we decided to do it from 0 to 300\n",
    "clean_data_binned = []\n",
    "#we create bins to divide the information in equaly sized groups\n",
    "for d in clean_data:\n",
    "    binned_data_i = {k: d[k] for k in ['class', 'superclass', 'subclass']}\n",
    "    spec = np.array([[float(sp) for sp in s.split(':')] for s in d['spectrum'].split()])\n",
    "    n_bin = np.digitize(spec[:, 0], bins)\n",
    "    all_values_for_bin_x = [np.array(spec[:, 0][n_bin == i]) for i in range(1, len(bins))]\n",
    "    all_values_for_bin_x = [v.mean() if len(v) else 0 for v in all_values_for_bin_x]\n",
    "    all_values_for_bin = [np.array(spec[:, 1][n_bin == i]) for i in range(1, len(bins))]\n",
    "    all_values_for_bin = [v if len(v) else np.array([0]) for v in all_values_for_bin ]\n",
    "    all_values_for_bin_max = [v.max() for v in all_values_for_bin]\n",
    "    binned_data_i['spectrum'] = [all_values_for_bin_x, all_values_for_bin_max]\n",
    "    clean_data_binned.append(binned_data_i)\n",
    "    if plot:\n",
    "        plt.hist(all_values_for_bin_x, bins=bins, weights=all_values_for_bin_max)\n",
    "        plt.plot(spec[:, 0], spec[:, 1], 'r')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING DICTIONARY FOR OUR FUNTIONS\n",
    "spectrum = [c['spectrum'][1] for c in clean_data_binned]\n",
    "superclass_d = [c['superclass'] for c in clean_data_binned]\n",
    "classes_d = [c['class'] for c in clean_data_binned]\n",
    "subclasses_d = [c['subclass'] for c in clean_data_binned]\n",
    "\n",
    "# USING DEFINED HIGHER FUNCTION 'CHANGECLASS'\n",
    "superclass = changeclass(superclass_d) \n",
    "classes = changeclass(classes_d)\n",
    "subclasses = changeclass(subclasses_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPHS WITH AMOUNT OF EACH TYPE OF SUBCLASS, CLASS AND SUPERCLASS IN THE DATA\n",
    "#showclass(superclass_d)\n",
    "#showclass(classes_d)\n",
    "#showclass(subclasses_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMLY SHUFFLE DATA\n",
    "packed_data = list(zip(spectrum, superclass, classes, subclasses))\n",
    "random.shuffle(packed_data)\n",
    "spectrum, superclass, classes, subclasses = zip(*packed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA TO TRAIN_DATA AND TEST_DATA\n",
    "spectrum_train   = spectrum[:TRAINED_DATA]\n",
    "spectrum_test    = spectrum[TRAINED_DATA:]\n",
    "superclass_train = superclass[:TRAINED_DATA]\n",
    "superclass_test  = superclass[TRAINED_DATA:]\n",
    "classes_train    = classes[:TRAINED_DATA]\n",
    "classes_test     = classes[TRAINED_DATA:]\n",
    "subclasses_train = subclasses[:TRAINED_DATA]\n",
    "subclasses_test  = subclasses[TRAINED_DATA:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPERCLASSES TRAINING PART\n",
    "#\n",
    "#\n",
    "# 20 Different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DECISION TREE CLASSIFIER\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "model_tree = model_tree.fit(spectrum_train, superclass_train)\n",
    "print(\"Trees model without setting parameters:\")\n",
    "model_tree_score = model_tree.score(spectrum_test, superclass_test)\n",
    "print(model_tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES TRAINING SUPERCLASSES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(spectrum_train, superclass_train)\n",
    "print(\"Naive Bayes model without setting parameters:\")\n",
    "model_nb_score = model_nb.score(spectrum_test, superclass_test)\n",
    "print(model_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN TRAINING SUPERCLASSES # LONGEST\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(spectrum_train, superclass_train)\n",
    "print(\"KNN model without setting parameters:\")\n",
    "model_knn_score = model_knn.score(spectrum_test, superclass_test)\n",
    "print(model_knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM KERNEL TRAINING SUPERCLASSES\n",
    "model_svm = svm.SVC(gamma='scale',probability=True)\n",
    "model_svm.fit(spectrum_train, superclass_train)\n",
    "print(\"SVM model without setting parameters:\")\n",
    "model_svm_score = model_svm.score(spectrum_test, superclass_test)\n",
    "print(model_svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES CLASSIFIER\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_rf = ExtraTreesClassifier(n_estimators = 100)\n",
    "model_rf.fit(spectrum_train, superclass_train)\n",
    "print(\"Extra Trees model without setting parameters:\")\n",
    "model_rf_score = model_rf.score(spectrum_test, superclass_test)\n",
    "print(model_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_Label = np.zeros((5,1))\n",
    "Occuring_Label = np.zeros((21, 2))\n",
    "#The sum of all scores(total score) is used as a way of normalizing the  score of each model given_model_score/total score\n",
    "\n",
    "total_score = model_nb_score + model_knn_score + model_svm_score + model_rf_score + model_tree_score\n",
    "\n",
    "Weight_Label[0,0] = model_nb_score / total_score\n",
    "Weight_Label[1,0] = model_knn_score / total_score\n",
    "Weight_Label[2,0] = model_svm_score / total_score\n",
    "Weight_Label[3,0] = model_rf_score / total_score\n",
    "Weight_Label[4,0] = model_tree_score / total_score\n",
    "\n",
    "for i in range(0,21):\n",
    "    Occuring_Label[i,0] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalPrediction = []\n",
    "Predict_Label = []\n",
    "\n",
    "per_class_accuracy = {k: [] for k in list(set(superclass_test))}\n",
    "per_class_accuracy_ET = {k: [] for k in list(set(superclass_test))}\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    Predict_NB = model_nb.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_KNN = model_knn.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_SVM = model_svm.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_RF = model_rf.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_TREE = model_tree.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    \n",
    "    Predict_Label = [Predict_NB,Predict_KNN,Predict_SVM,Predict_RF,Predict_TREE]\n",
    "    #We use the score of each classifiers as weight for them\n",
    "    #to give importance to each classifier and all those importance together \n",
    "    \n",
    "    \n",
    "    for j in range(0,21):\n",
    "        for k in range(0,4):\n",
    "            if Predict_Label[k] == j:\n",
    "                Occuring_Label[j,1] += Occuring_Label[j,1] + Weight_Label[k,0]\n",
    "    Score = np.where(Occuring_Label[:,1] == np.amax(Occuring_Label[:,1], axis=0))[0]\n",
    "\n",
    "    FinalPrediction.append(Score[0])\n",
    "    for j in range(0,21):\n",
    "        Occuring_Label[j,1] = 0\n",
    "        \n",
    "    accuracy = Score[0] == superclass_test[i] #boolean\n",
    "    accuracy_ET = Predict_RF == superclass_test[i] #boolean\n",
    "    per_class_accuracy[superclass_test[i]].append(accuracy) #accuracy of each individual label\n",
    "    per_class_accuracy_ET[superclass_test[i]].append(accuracy_ET) #accuracy of each individual label\n",
    "\n",
    "per_class_accuracy_ET_Done = {k: [v[0] for v in val] for k, val in per_class_accuracy_ET.items()} #retranslate the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE THE PERCENTAGE OF ACCURACY FOR EACH LABEL\n",
    "showaccuracy(per_class_accuracy, per_class_accuracy_ET_Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute each score by comparing ground truth with predictions\n",
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    if(FinalPrediction[i] == superclass_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "\n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)\n",
    "print('\\n')\n",
    "\n",
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "model = model_rf.predict(spectrum_test[:COMBINED_CLASSIFICATION_SAMPLES])\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    #print(FinalPrediction[i], superclass_test[i], model[i])\n",
    "    if(model[i] == superclass_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "\n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES TRAINING PART\n",
    "#\n",
    "#\n",
    "# 203 Different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE CLASSIFIER\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "model_tree = model_tree.fit(spectrum_train, classes_train)\n",
    "print(\"Trees model without setting parameters:\")\n",
    "model_tree_score = model_tree.score(spectrum_test, classes_test)\n",
    "print(model_tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES TRAINING SUPERCLASSES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(spectrum_train, classes_train)\n",
    "print(\"Naive Bayes model without setting parameters:\")\n",
    "model_nb_score = model_nb.score(spectrum_test, classes_test)\n",
    "print(model_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN TRAINING SUPERCLASSES\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(spectrum_train, classes_train)\n",
    "print(\"KNN model without setting parameters:\")\n",
    "model_knn_score = model_knn.score(spectrum_test, classes_test)\n",
    "print(model_knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM KERNEL TRAINING SUPERCLASSES\n",
    "model_svm = svm.SVC(gamma='scale',probability=True)\n",
    "model_svm.fit(spectrum_train, classes_train)\n",
    "print(\"SVM model without setting parameters:\")\n",
    "model_svm_score = model_svm.score(spectrum_test, classes_test)\n",
    "print(model_svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES CLASSIFIER\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_rf = ExtraTreesClassifier(n_estimators = 100)\n",
    "model_rf.fit(spectrum_train, classes_train)\n",
    "print(\"Extra Trees model without setting parameters:\")\n",
    "model_rf_score = model_rf.score(spectrum_test, classes_test)\n",
    "print(model_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_Label = np.zeros((5,1))\n",
    "Occuring_Label = np.zeros((203, 2))\n",
    "\n",
    "Weight_Label[0,0] = model_nb_score\n",
    "Weight_Label[1,0] = model_knn_score\n",
    "Weight_Label[2,0] = model_svm_score\n",
    "Weight_Label[3,0] = model_rf_score\n",
    "Weight_Label[4,0] = model_tree_score\n",
    "\n",
    "for i in range(0,203):\n",
    "    Occuring_Label[i,0] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalPrediction = []\n",
    "Predict_Label = []\n",
    "\n",
    "per_class_accuracy = {k: [] for k in list(set(superclass_test))}\n",
    "per_class_accuracy_ET = {k: [] for k in list(set(superclass_test))}\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    Predict_NB = model_nb.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_KNN = model_knn.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_SVM = model_svm.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_RF = model_rf.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_TREE = model_tree.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    \n",
    "    Predict_Label = [Predict_NB,Predict_KNN,Predict_SVM,Predict_RF,Predict_TREE]\n",
    "    #We use the score of each classifiers as weight for them\n",
    "    #to give importance to each classifier and all those importance together \n",
    "    \n",
    "    \n",
    "    for j in range(0,203):\n",
    "        for k in range(0,4):\n",
    "            if Predict_Label[k] == j:\n",
    "                Occuring_Label[j,1] += Occuring_Label[j,1] + Weight_Label[k,0]\n",
    "    Score = np.where(Occuring_Label[:,1] == np.amax(Occuring_Label[:,1], axis=0))[0]\n",
    "\n",
    "    FinalPrediction.append(Score[0])\n",
    "    for j in range(0,203):\n",
    "        Occuring_Label[j,1] = 0\n",
    "        \n",
    "    accuracy = Score[0] == superclass_test[i] #boolean\n",
    "    accuracy_ET = Predict_RF == superclass_test[i] #boolean\n",
    "    per_class_accuracy[superclass_test[i]].append(accuracy) #accuracy of each individual label\n",
    "    per_class_accuracy_ET[superclass_test[i]].append(accuracy_ET) #accuracy of each individual label\n",
    "\n",
    "per_class_accuracy_ET_Done = {k: [v[0] for v in val] for k, val in per_class_accuracy_ET.items()} #retranslate the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    if(FinalPrediction[i] == classes_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "                \n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)\n",
    "print('\\n')\n",
    "\n",
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "model = model_rf.predict(spectrum_test[:COMBINED_CLASSIFICATION_SAMPLES])\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    #print(FinalPrediction[i], superclass_test[i], model[i])\n",
    "    if(model[i] == classes_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "        \n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBCLASSES TRAINING PART\n",
    "#\n",
    "#\n",
    "# 375 Different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE CLASSIFIER\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "model_tree = model_tree.fit(spectrum_train, subclasses_train)\n",
    "print(\"Trees model without setting parameters:\")\n",
    "model_tree_score = model_tree.score(spectrum_test, subclasses_test)\n",
    "print(model_tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES TRAINING SUPERCLASSES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(spectrum_train, subclasses_train)\n",
    "print(\"Naive Bayes model without setting parameters:\")\n",
    "model_nb_score = model_nb.score(spectrum_test, subclasses_test)\n",
    "print(model_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN TRAINING SUPERCLASSES\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(spectrum_train, subclasses_train)\n",
    "print(\"KNN model without setting parameters:\")\n",
    "model_knn_score = model_knn.score(spectrum_test, subclasses_test)\n",
    "print(model_knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM KERNEL TRAINING SUPERCLASSES\n",
    "model_svm = svm.SVC(gamma='scale',probability=True)\n",
    "model_svm.fit(spectrum_train, subclasses_train)\n",
    "print(\"SVM model without setting parameters:\")\n",
    "model_svm_score = model_svm.score(spectrum_test, subclasses_test)\n",
    "print(model_svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES CLASSIFIER\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_rf = ExtraTreesClassifier(n_estimators = 100)\n",
    "model_rf.fit(spectrum_train, subclasses_train)\n",
    "print(\"Extra Trees model without setting parameters:\")\n",
    "model_rf_score = model_rf.score(spectrum_test, subclasses_test)\n",
    "print(model_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_Label = np.zeros((5,1))\n",
    "Occuring_Label = np.zeros((375, 2))\n",
    "\n",
    "Weight_Label[0,0] = model_nb_score\n",
    "Weight_Label[1,0] = model_knn_score\n",
    "Weight_Label[2,0] = model_svm_score\n",
    "Weight_Label[3,0] = model_rf_score\n",
    "Weight_Label[4,0] = model_tree_score\n",
    "\n",
    "for i in range(0,375):\n",
    "    Occuring_Label[i,0] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalPrediction = []\n",
    "Predict_Label = []\n",
    "\n",
    "per_class_accuracy = {k: [] for k in list(set(superclass_test))}\n",
    "per_class_accuracy_ET = {k: [] for k in list(set(superclass_test))}\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    Predict_NB = model_nb.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_KNN = model_knn.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_SVM = model_svm.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_RF = model_rf.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    Predict_TREE = model_tree.predict(np.array(spectrum_test[i]).reshape(1, -1))\n",
    "    \n",
    "    Predict_Label = [Predict_NB,Predict_KNN,Predict_SVM,Predict_RF,Predict_TREE]\n",
    "    #We use the score of each classifiers as weight for them\n",
    "    #to give importance to each classifier and all those importance together \n",
    "    \n",
    "    \n",
    "    for j in range(0,375):\n",
    "        for k in range(0,4):\n",
    "            if Predict_Label[k] == j:\n",
    "                Occuring_Label[j,1] += Occuring_Label[j,1] + Weight_Label[k,0]\n",
    "    Score = np.where(Occuring_Label[:,1] == np.amax(Occuring_Label[:,1], axis=0))[0]\n",
    "\n",
    "    FinalPrediction.append(Score[0])\n",
    "    for j in range(0,375):\n",
    "        Occuring_Label[j,1] = 0\n",
    "        \n",
    "    accuracy = Score[0] == superclass_test[i] #boolean\n",
    "    accuracy_ET = Predict_RF == superclass_test[i] #boolean\n",
    "    per_class_accuracy[superclass_test[i]].append(accuracy) #accuracy of each individual label\n",
    "    per_class_accuracy_ET[superclass_test[i]].append(accuracy_ET) #accuracy of each individual label\n",
    "\n",
    "per_class_accuracy_ET_Done = {k: [v[0] for v in val] for k, val in per_class_accuracy_ET.items()} #retranslate the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    if(FinalPrediction[i] == subclasses_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "                \n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)\n",
    "print('\\n')\n",
    "\n",
    "pluscounter = 0\n",
    "minuscounter = 0\n",
    "model = model_rf.predict(spectrum_test[:COMBINED_CLASSIFICATION_SAMPLES])\n",
    "\n",
    "for i in range(0,COMBINED_CLASSIFICATION_SAMPLES):\n",
    "    #print(FinalPrediction[i], superclass_test[i], model[i])\n",
    "    if(model[i] == subclasses_test[i]):\n",
    "        pluscounter += 1\n",
    "    else:\n",
    "        minuscounter += 1\n",
    "        \n",
    "print(pluscounter/COMBINED_CLASSIFICATION_SAMPLES)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
